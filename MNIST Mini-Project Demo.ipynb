{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST Mini-Project Demo.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dMQwSG85TEes","colab_type":"text"},"source":["**Note: Please make your own copy of this notebook to run and execute, thank you!**\n","\n","1.   Go to the menu tab on the top left corner\n","2.   Click on \"File\"\n","3.   Under the File tab menu click on \"Save a copy in Drive...\""]},{"cell_type":"markdown","metadata":{"id":"M4_zWpywyGeI","colab_type":"text"},"source":["## Tip for running multiple code cells\n","A useful tool when running code in Colaboratory is the **Runtime tab**. Clicking on this tab will open a menu with various options that will allow you to run multiple code cells simultaneously. For example, \"Run before\" will run all the code cells before the currently selected cell in order starting with the first. This is particularly helpful if you run into an error while editing your code and you want to ensure all the variables and data have been initialized properly prior to the cell you're working on."]},{"cell_type":"markdown","metadata":{"id":"gR6cluHY5JpI","colab_type":"text"},"source":["# Load libraries and dataset"]},{"cell_type":"code","metadata":{"id":"ptR9JyVb5I53","colab_type":"code","outputId":"b17177ba-f791-4a3a-f32d-e13d0b0f61e6","executionInfo":{"status":"ok","timestamp":1545698488829,"user_tz":480,"elapsed":1769,"user":{"displayName":"Tairi Delgado","photoUrl":"https://lh6.googleusercontent.com/-l4lv-T3P6-c/AAAAAAAAAAI/AAAAAAAABIA/4wtQ8ehIzZw/s64/photo.jpg","userId":"11498478730259043793"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.python.framework import tensor_shape\n","import keras\n","from keras.datasets import mnist\n","from keras.optimizers import SGD\n","from keras.utils import print_summary, to_categorical\n","from google.colab import files"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Q6PO0a3XiHRz","colab_type":"text"},"source":["[MNIST Dataset:](http://yann.lecun.com/exdb/mnist/)\n","\n","The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set for evaluation purposes of 10,000. It is a subset of a larger set available from NIST. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."]},{"cell_type":"markdown","metadata":{"id":"eKn61R19hsFx","colab_type":"text"},"source":["Split our data into features, labels, training, and testing data."]},{"cell_type":"code","metadata":{"id":"NeT_9JVw4xiG","colab_type":"code","outputId":"ed8a2448-a4be-4c43-d947-519a91edab1b","executionInfo":{"status":"ok","timestamp":1545698502219,"user_tz":480,"elapsed":1433,"user":{"displayName":"Tairi Delgado","photoUrl":"https://lh6.googleusercontent.com/-l4lv-T3P6-c/AAAAAAAAAAI/AAAAAAAABIA/4wtQ8ehIzZw/s64/photo.jpg","userId":"11498478730259043793"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Load the MNIST dataset from Keras\n","# Split dataset into testing, traing, features, and labels\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QnVpEkjTBjmN","colab_type":"text"},"source":["# Exploratory Analysis"]},{"cell_type":"markdown","metadata":{"id":"1vOz3iY_hyuH","colab_type":"text"},"source":["Now let's take a look at the size, shape, and dimensions of our intial data."]},{"cell_type":"code","metadata":{"id":"pqxjd6jhBoev","colab_type":"code","outputId":"4abff594-b8eb-45ba-c399-1d49c0f8f4dd","executionInfo":{"status":"ok","timestamp":1545698506903,"user_tz":480,"elapsed":1094,"user":{"displayName":"Tairi Delgado","photoUrl":"https://lh6.googleusercontent.com/-l4lv-T3P6-c/AAAAAAAAAAI/AAAAAAAABIA/4wtQ8ehIzZw/s64/photo.jpg","userId":"11498478730259043793"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Display the size and shape of features, labels, training, and testing datasets\n","print(\"Size and shape of the training features are (training data size, image width, image height): {}\".format(x_train.shape))\n","print(\"Size and shape of the training labels are (training data size): {}\".format(y_train.shape))\n","print(\"Size and shape of the testing features are (testing data size, image width, image height): {}\".format(x_test.shape))\n","print(\"Size and shape of the testing labels are (testing data size): {}\".format(y_test.shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Size and shape of the training features are (training data size, image width, image height): (60000, 28, 28)\n","Size and shape of the training labels are (training data size): (60000,)\n","Size and shape of the testing features are (testing data size, image width, image height): (10000, 28, 28)\n","Size and shape of the testing labels are (testing data size): (10000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bYDOn1Jgij0V","colab_type":"text"},"source":["In case you are interested in looking at individual images from the dataset, run the snippet of code below. You can change the index from 9 to another index number within the training data to see what image shows up that will be fed to our network."]},{"cell_type":"code","metadata":{"id":"G1O50g42BalH","colab_type":"code","outputId":"4b08730c-2ff2-4c20-e11d-2de496033cbc","executionInfo":{"status":"ok","timestamp":1545698532964,"user_tz":480,"elapsed":350,"user":{"displayName":"Tairi Delgado","photoUrl":"https://lh6.googleusercontent.com/-l4lv-T3P6-c/AAAAAAAAAAI/AAAAAAAABIA/4wtQ8ehIzZw/s64/photo.jpg","userId":"11498478730259043793"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"source":["# This samples the 9-th image from the training dataset.\n","index = 10 # feel free to change this index value to see another image\n","image = x_train[index].reshape(28,28)\n","\n","# Use the matplotlib library to display the image and its label (do not modify)\n","plt.figure(figsize=(3,3)) # Initialize the size of the plot frame\n","plt.imshow(image); plt.grid('off');plt.axis('off') # Feed image values to plot\n","plt.show() # Generate plot onto screen"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAMMAAADDCAYAAAA/f6WqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABQBJREFUeJzt3T9oVFkYxuGbdVEsVAxiZ6MIKhZW\nWggWKrYi2KhgIViIlgGxsk1lISJoJxaCbSy0jKDGVAqCVlEQEQmIfyJpItliX2zmGzazmclkMs9T\nflzuHAg/DjncuTOyuLi42ADNX/1eAKwWYoAQA4QYIMQAIQYIMUCIAUIMEGKAEAOEGCDEACEGCDFA\niAFCDBBigBADhBggxAAhBggxQIgBQgwQYoAQA4QYIMQA8Xe/FzAMvnz5Us6fPHlSzsfHx8v50aNH\ny/nBgwc7Ws+5c+daZuvWrevoHmuRnQFCDBBigBADhBggRvymW3c9evSoZXb27Nny2p8/f/Z6OaW3\nb9+2zPbs2dOHlawudgYIMUCIAUIMEGKAcJrUZfPz8y2zXbt2ldd+/vy518spjY6OtswmJyfLa/fv\n39/r5awadgYIMUCIAUIMEGKA8E23Ltu4cWPL7M6dO+W1Z86cKee/fv0q5zt37iznMzMzS1zdv75+\n/doym5iYKK91mgRDSAwQYoAQA4QYIDyb1EeHDx8u58+fPy/n7d6PND09vey1VCdMTdM0W7duXfa9\nB4WdAUIMEGKAEAOEGCCcJvXR1NRUOR8bGyvnz54969la2r0pfPv27T37zNXGzgAhBggxQIgBQgwQ\nTpNWobm5uXJ+/Pjxcv7y5ctlf+bFixfL+d27d5d970FhZ4AQA4QYIMQA4VUxffT06dNy3u4f4m58\niaedY8eO9ezeg8LOACEGCDFAiAFCDBAex+iy2dnZltmJEyfKa9+8eVPOFxYWurqmpfCqGDsD/CEG\nCDFAiAFCDBCeTeqy9+/ft8zevXtXXtuPU6N2bt68Wc6vX7++wivpHzsDhBggxAAhBggxQDhN6rLq\np6bu379fXnv+/PlyPj8/39U1LcWnT59W/DNXGzsDhBggxAAhBggxQDhNWgGnT58u57t37y7nP378\n6Oj+v3//LuenTp0q59++fevo/sPCzgAhBggxQIgBQgwQ3pu0BrT7E96+fbucX7lypWW2d+/e8toX\nL16U8y1btixxdYPDzgAhBggxQIgBQgwQnk1aA9o9m1SdGrWzYcOGcj4yMvK/1jSI7AwQYoAQA4QY\nIPwDvQbcuHFj2fcYGxsr55s3b172vQeFnQFCDBBigBADhBgghu7LPe1e6nvp0qVyfuHChXJ+5MiR\nrq1pqebm5sr5jh07ynknr4Txo+h2BvhDDBBigBADhBgghu7ZpKtXr5bze/fulfNXr16V84cPH5bz\nbdu2tcxGR0fLaz9+/FjOP3z4UM6vXbtWzjt9kfD4+HjLbNOmTR3dYy2yM0CIAUIMEGKAEAPE0D2b\nNDMzU84vX75czh8/ftzR/aufpjp06FB57cTERDn//v17R5/Z7nUuBw4cKOdTU1Mts/Xr13f0mWuR\nnQFCDBBigBADhBgghu40qZ3qeZ2maZp9+/aV85MnT/ZyOR2pnodqmqaZnZ1d4ZUMNjsDhBggxAAh\nBggxQDhN+g8LCwvl/MGDB0u+x/T0dDm/detWR2tp9w6j169fl/N271OiZmeAEAOEGCDEACEGCKdJ\nEHYGCDFAiAFCDBBigBADhBggxAAhBggxQIgBQgwQYoAQA4QYIMQAIQYIMUCIAUIMEGKAEAOEGCDE\nACEGCDFAiAFCDBBigBADhBggxAAhBggxQIgBQgwQYoAQA4QYIMQAIQYIMUCIAUIMEGKAEAPEP2qe\nANRQJNd4AAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7f54b5455908>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"P5CfbUq55sXB","colab_type":"text"},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"Inqm4YGEirVF","colab_type":"text"},"source":["Normally when dealing with real-world data it does not come perfectly packaged and ready to use by our models. In order to properly train them, we need to let it know the number of classes we need to label, what they are, and how the model should output its predictions.\n","\n","Since we have ten image classes, we don't want a single prediction. Instead we ideally would like the model to predict how ***confident*** the image fits between all ten image classes (not just the single best prediction) between 0 and 1 where all prediction values must add up to 1.\n","\n","To do this we'll use one-hot encodings. One-hot encodings allow us to format our labels so the model can distinguish an image between all the available classes. For instance if we have three images classes - 'man', 'woman', 'dog' - we would have a label with three elements. If an image is a dog the label would be formatted as [0,0,1] since it is not a man or woman. Our model will then to output a list of probablities for each class label that all add up to 1, but if modeled correctly will have a very high probability on the correct label."]},{"cell_type":"code","metadata":{"id":"OAJ8fkYu6cfa","colab_type":"code","colab":{}},"source":["# Specify the number of class labels in our data\n","num_classes = 10\n","\n","# Keep original labels\n","labels_test = y_test\n","\n","# Labels are stored as unique integers\n","# Convert labels into unique one-hot encodings of length num_class\n","# Each label will then be converted to a series of zeros with one unique column containing a one for a unique label\n","# example 10000000000 or 0001000000, etc (don't worry if you are not familiar with this step)\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W56DM8gpoSSK","colab_type":"text"},"source":["If we take a closer look at our images, we can see the pixel values range from 0-255. These value ranges give us a bunch of gray values to quantify how 'black' or 'white' the pixel is. These seem like an arbitrary scale for our models to understand. For instance, imagine if you were given a grade of 34 for a history class, 56 for math, and 46 for English Literature. Each of these grades has a specific meaning for each course, but without context would be hard for you to understand. This is why we convert absolute values into a relative standing such as letter grades scored between 0-100. Just like humans, neural networks have a hard time understanding relative values, so we want convert our pixel values into a range from 0-1, thus making it easier for the network to learn."]},{"cell_type":"code","metadata":{"id":"plB7I_g_6lRC","colab_type":"code","colab":{}},"source":["# Our input data is pixels from images where each pixel value is between ranges 0-255\n","# Range of values make it difficult for our network to learn\n","# Convert raw pixel values into values between 0-1\n","x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n","x_train /= 250.0\n","x_test /= 250.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cyxOCqloh4JD","colab_type":"code","outputId":"fff647eb-9b55-418a-cc60-481d02ebcdd1","executionInfo":{"status":"ok","timestamp":1545698544776,"user_tz":480,"elapsed":331,"user":{"displayName":"Tairi Delgado","photoUrl":"https://lh6.googleusercontent.com/-l4lv-T3P6-c/AAAAAAAAAAI/AAAAAAAABIA/4wtQ8ehIzZw/s64/photo.jpg","userId":"11498478730259043793"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Display the size and shape of features, labels, training, and testing datasets\n","print(\"Size and shape of the training features are (training data size, image width, image height, image color depth): {}\".format(x_train.shape))\n","print(\"Size and shape of the training labels are (training data label size, number of class labels): {}\".format(y_train.shape))\n","print(\"Size and shape of the testing features are (test data size, image width, image height, image color depth): {}\".format(x_test.shape))\n","print(\"Size and shape of the testing labels are (test data size, number of class labels): {}\".format(y_test.shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Size and shape of the training features are (training data size, image width, image height, image color depth): (60000, 28, 28, 1)\n","Size and shape of the training labels are (training data label size, number of class labels): (60000, 10)\n","Size and shape of the testing features are (test data size, image width, image height, image color depth): (10000, 28, 28, 1)\n","Size and shape of the testing labels are (test data size, number of class labels): (10000, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5xLXAZ0V5tIw","colab_type":"text"},"source":["# Model Building"]},{"cell_type":"markdown","metadata":{"id":"9cn-M_N2oy6d","colab_type":"text"},"source":["In our next step, we are going to create a couple of advanced neural network layers to include a bunch of tensorflow subroutines and techniques. If you have not heard of some of the terms used in this notebook such as convolutions, maxpooling, or softmax, don't worry as you are not expected to know what these functions do yet! Instead we are going to abstract away these advanced techniques so you can focus on the much bigger picture - how an image recognition system might be built and how the number of neurons and layers effect our model's training and performance."]},{"cell_type":"code","metadata":{"id":"C5xKplV-MEKD","colab_type":"code","colab":{}},"source":["# Convolutional Neural Network with MaxPooling Layer Wrapper\n","class ConvMaxLayer(tf.keras.Model):\n","  \n","    # Initialize our variables\n","    def __init__(self, filters, dropout_rate):\n","        super(ConvMaxLayer, self).__init__()\n","        self.filters = filters\n","        self.kernel_size = 3\n","        self.conv_stride = 1\n","        self.padding = 'valid'\n","        self.pad_size = 0\n","        self.pool_size = 2\n","        self.maxpool_stride = 2\n","        self.dropout_rate = dropout_rate\n","        \n","    # Define our layers\n","    def build(self, input_shape):\n","        self.conv2D = tf.keras.layers.Conv2D(filters=self.filters, kernel_size=self.kernel_size, strides=self.conv_stride, padding=self.padding, input_shape=input_shape)\n","        self.batchnorm = tf.keras.layers.BatchNormalization()\n","        self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=self.pool_size, strides=self.maxpool_stride, padding=self.padding)\n","        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n","\n","    # Computation of network layers\n","    def call(self, inputs):\n","        x = self.conv2D(inputs)\n","        x = self.batchnorm(x, training=True)\n","        x = tf.nn.relu(x)\n","        x = self.maxpool(x)\n","        x = self.dropout(x)\n","        return (x)\n","    \n","    # Define output shape\n","    def compute_output_shape(self, input_shape):\n","      # Input Dimensions\n","      w1 = input_shape[1] # Width\n","      h1 = input_shape[2] # Height\n","      d1 = input_shape[3] # Depth\n","      \n","      # Convolution Hyperparameters\n","      k1 = self.filters # number of filters\n","      f1 = self.kernel_size # spatial extent\n","      s1 = self.conv_stride # strides\n","      p1 = self.pad_size # padding\n","      \n","      # Convolution Output Dimensions\n","      w2 = (int(w1 - f1 + 2*p1)/s1) + 1\n","      h2 = (int(h1 - f1 + 2*p1)/s1) + 1\n","      d2 = k1\n","      \n","      # Maxpooling Dimensions Hyperparameters\n","      f2 = self.pool_size\n","      s2 = self.maxpool_stride\n","      \n","      # Maxpooling Output Dimensions\n","      w3 = int(((w2 - f2)/s2) + 1)\n","      h3 = int(((h2 - f2)/s2) + 1)\n","      d3 = d2\n","      return (input_shape[0], w3, h3, d3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"98tRvOc7FPq-","colab_type":"code","colab":{}},"source":["# Forward-Feed Neural Network Layer\n","class ForwardLayer(tf.keras.Model):\n","  \n","    # Initialize our variables\n","    def __init__(self, size, dropout_rate):\n","        super(ForwardLayer, self).__init__()\n","        self.size = size\n","        self.dropout_rate = dropout_rate\n","        \n","    # Define our layers\n","    def build(self, input_shape):\n","        self.dense = tf.keras.layers.Dense(self.size, input_shape=input_shape)\n","        self.batchnorm = tf.keras.layers.BatchNormalization()\n","        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n","    \n","    # Computation of network layers\n","    def call(self, inputs):\n","        x = self.dense(inputs)\n","        x = self.batchnorm(x)\n","        x = tf.nn.relu(x)\n","        x = self.dropout(x)\n","        return x\n","      \n","    # Define output shape\n","    def compute_output_shape(self, input_shape):\n","      return (input_shape[0], self.size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZMp9ZPU8rMpo","colab_type":"text"},"source":["Now that we have abstracted away some details of tensorflow, we can outline and define our image recognition network by adding one layer at a time."]},{"cell_type":"code","metadata":{"id":"qngHXbGZ7V-3","colab_type":"code","colab":{}},"source":["# Initialize our network object\n","net = tf.keras.Sequential()\n","\n","# Layer One (Convolutional MaxPooling Layer)\n","net.add(ConvMaxLayer(filters=32, dropout_rate=0.3))\n","\n","# Layer Two (Convolutional MaxPooling Layer)\n","net.add(ConvMaxLayer(filters=64, dropout_rate=0.3))\n","\n","# Flatten (to make it easier for the output of layer two to transition into layer three)\n","net.add(tf.keras.layers.Flatten())\n","\n","# Layer Three (Forward-feed Layer)\n","net.add(ForwardLayer(64, 0.1))\n","\n","# Layer Four (Forward-feed Layer)\n","net.add(ForwardLayer(32, 0))\n","\n","# Output Layer\n","net.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rCG-LaSetPnc","colab_type":"text"},"source":["Now that you have your model defined, we'll need to actually build it and define how it will learn. To do so, we'll need to call the network's compile function to provide it the loss, optimization, and metric parameters."]},{"cell_type":"code","metadata":{"id":"bQ7gNoIHMC6F","colab_type":"code","outputId":"85b79427-b294-4b58-fd86-8401054c8c6b","executionInfo":{"status":"ok","timestamp":1545698565221,"user_tz":480,"elapsed":287,"user":{"displayName":"Tairi Delgado","photoUrl":"https://lh6.googleusercontent.com/-l4lv-T3P6-c/AAAAAAAAAAI/AAAAAAAABIA/4wtQ8ehIzZw/s64/photo.jpg","userId":"11498478730259043793"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Compiles our model with the specified loss, optimization, and metric parameters\n","net.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print('Model is done compiling!')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model is done compiling!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HvwERE9u5zCc","colab_type":"text"},"source":["# Train Model"]},{"cell_type":"markdown","metadata":{"id":"iYgS54NruKHE","colab_type":"text"},"source":["Our next step is to define the batch size and number of epochs to train before we call the network's fit procedure with all our data and training parameters listed below. \n","\n","The batch size refers to how many samples (in this case, samples = images) are processed by the model before the internal weights are updated. Naturally, this means the batch size will be anywhere between 1 (just one sample) and the size of the training set (all the samples in the training set). It is generally advantageous to set the batch size to a relatively small value such as 32 or 64 since that limits how much memory we use on each iteration. That is, we only load a handful of images at a time rather than all of them at once. \n","\n","\"Epoch\" is simply another word for iteration. The more epochs we run, the more the model is able to train and (hopefully) the lower the error rate will be. Of course, training takes time, so for this project we'll limit the number of epochs to a fairly small number. In real applications, however, the number of epochs is often in the hundreds or thousands."]},{"cell_type":"code","metadata":{"id":"pRpe2uMqMFU-","colab_type":"code","outputId":"2f6dfc56-57a5-49ea-faa1-32cbb549f841","executionInfo":{"status":"ok","timestamp":1545698993275,"user_tz":480,"elapsed":425848,"user":{"displayName":"Tairi Delgado","photoUrl":"https://lh6.googleusercontent.com/-l4lv-T3P6-c/AAAAAAAAAAI/AAAAAAAABIA/4wtQ8ehIzZw/s64/photo.jpg","userId":"11498478730259043793"}},"colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["# Define our learning parameters and feed data towards our model for training\n","net.fit(x_train, y_train, batch_size=32, epochs=3, validation_split=0.2, shuffle=True)\n","net.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 48000 samples, validate on 12000 samples\n","Epoch 1/3\n","48000/48000 [==============================] - 140s 3ms/step - loss: 0.1553 - acc: 0.9523 - val_loss: 0.0677 - val_acc: 0.9797\n","Epoch 2/3\n","48000/48000 [==============================] - 139s 3ms/step - loss: 0.0585 - acc: 0.9819 - val_loss: 0.0522 - val_acc: 0.9850\n","Epoch 3/3\n","48000/48000 [==============================] - 144s 3ms/step - loss: 0.0439 - acc: 0.9862 - val_loss: 0.0621 - val_acc: 0.9832\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv_max_layer (ConvMaxLayer multiple                  448       \n","_________________________________________________________________\n","conv_max_layer_1 (ConvMaxLay multiple                  18752     \n","_________________________________________________________________\n","flatten (Flatten)            multiple                  0         \n","_________________________________________________________________\n","forward_layer (ForwardLayer) multiple                  102720    \n","_________________________________________________________________\n","forward_layer_1 (ForwardLaye multiple                  2208      \n","_________________________________________________________________\n","dense (Dense)                multiple                  330       \n","=================================================================\n","Total params: 124,458\n","Trainable params: 124,074\n","Non-trainable params: 384\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Pew-XhIFOJET","colab_type":"text"},"source":["# Test Model Performance"]},{"cell_type":"markdown","metadata":{"id":"P9zjLnm0uSo3","colab_type":"text"},"source":["Now that we trained our model here is the moment of truth. A model that only performs well on training data is not a very good model! Let's see how well the model does on testing data to get an idea of how it might perform out in the wild. "]},{"cell_type":"code","metadata":{"id":"TO0HRhrnOIb4","colab_type":"code","colab":{}},"source":["# Use the networks evaluate function to see how well the model predicts the correct labels on the testing dataset\n","scores = net.evaluate(x_test, y_test, verbose=0)\n","\n","# Report the final accuracy score\n","print('Test Loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AURFUo3ty-dY","colab_type":"text"},"source":["# Applications"]},{"cell_type":"markdown","metadata":{"id":"7Gjskw25fJdZ","colab_type":"text"},"source":["Alright let's see how our final model does on some individual digits!"]},{"cell_type":"code","metadata":{"id":"c03U8oY4Xssr","colab_type":"code","colab":{}},"source":["# Create plot and parameters to layout our images and predictions\n","labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","\n","num = 3\n","margin = 0.05\n","ind = np.arange(len(labels))\n","width = (1. - 2. * margin) / num\n","\n","fig, ax = plt.subplots(nrows=num, ncols=2)\n","fig.tight_layout()\n","fig.suptitle('Image Predictions', fontsize=20, y=1.1)\n","\n","# Loop through each image to plot and make a prediction\n","for i in range(num):\n","  image = x_test[i]\n","  label = labels_test[i]\n","  x = image.reshape(1,image.shape[0],image.shape[1],image.shape[2])\n","  pred = net.predict(x, batch_size=None, verbose=0, steps=None).flatten()\n","\n","  # Display image and correct label\n","  ax[i][0].imshow(image.squeeze())\n","  ax[i][0].set_title(\"Correct Label: {}\".format(label))\n","  ax[i][0].set_axis_off()\n","  \n","  # Display the predicted confidence in each label\n","  ax[i][1].barh(ind + margin, pred, width)\n","  ax[i][1].set_yticks(ind + margin)\n","  ax[i][1].set_yticklabels(labels)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CzRgSQdSLJM0","colab_type":"text"},"source":["**Interactive Demo:**\n","\n","Interested to see an interactive tool for digit recognition models? click on this [link](http://scs.ryerson.ca/~aharley/vis/fc/) to draw a digit and see how well a neural network guesses the correct answer!"]},{"cell_type":"markdown","metadata":{"id":"U2rze-GCma1I","colab_type":"text"},"source":["# Save Model"]},{"cell_type":"markdown","metadata":{"id":"jgmPKbAhpDD0","colab_type":"text"},"source":["Now that we are done with the demo feel free to save your model weights in case you decided you want to use them later. By downloading the h5 file we can use it at a later time to reload the weights instead of having to retrain from scratch! We'll show you in the next mini-project how to load a pre-trained model so stay tuned!"]},{"cell_type":"code","metadata":{"id":"2c0pfJFYmn4E","colab_type":"code","colab":{}},"source":["# Saves your trained model for use later\n","net.save_weights('final_mnist_weights.h5') # Saves just the weights (like we did earlier)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSX1q-xCmsFs","colab_type":"code","colab":{}},"source":["# Download the files to local computer drive\n","files.download('final_mnist_weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMB_dguoUnNH","colab_type":"text"},"source":["**Reflections:**\n","*   What might be a good reason to save the weights of our network?\n","*   If we reload the weights into a new model what do you think the model performance should be?\n","*   What if we continue to train the model?\n","\n","\n"]}]}