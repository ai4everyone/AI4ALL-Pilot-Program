{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR-10 Mini-Project Students.ipynb","provenance":[{"file_id":"1NDEWrTjvZTe9kusWhnR23IbQXS6opTpw","timestamp":1541783158804}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"oK0sK9WKTRJT","colab_type":"text"},"source":["**Note: Please make your own copy of this notebook to run and execute, thank you!**\n","\n","1.   Go to the menu tab on the top left corner\n","2.   Click on \"File\"\n","3.   Under the File tab menu click on \"Save a copy in Drive...\""]},{"cell_type":"markdown","metadata":{"id":"ghcnfFPXxz90","colab_type":"text"},"source":["## Tip for running multiple code cells\n","A useful tool when running code in Colaboratory is the **Runtime tab**. Clicking on this tab will open a menu with various options that will allow you to run multiple code cells simultaneously. For example, \"Run before\" will run all the code cells before the currently selected cell in order starting with the first. This is particularly helpful if you run into an error while editing your code and you want to ensure all the variables and data have been initialized properly prior to the cell you're working on."]},{"cell_type":"markdown","metadata":{"id":"aaKNDLT68sfj","colab_type":"text"},"source":["# Load libraries and dataset"]},{"cell_type":"markdown","metadata":{"id":"AQxY9clMdzRl","colab_type":"text"},"source":["**Documentation:**\n","\n","[Python 3 Documentation](https://docs.python.org/3/tutorial/index.html)\n","\n","[Numpy Documentation](https://docs.scipy.org/doc/numpy/user/quickstart.html)\n","\n","[Keras Documentation](https://keras.io/)\n","\n"]},{"cell_type":"code","metadata":{"id":"QrE6Vr4K6aD4","colab_type":"code","colab":{}},"source":["### DO NOT MODIFY ###\n","# Import Numpy, Matplotlib, and Keras Data Science libraries to perform most of the heavy lifting for us\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import keras\n","from keras.models import load_model\n","from keras.optimizers import SGD\n","from keras.utils import print_summary, to_categorical\n","from google.colab import files"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_u81mMGKdkHV","colab_type":"text"},"source":["**[CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html):**\n","\n","The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n","\n","The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. "]},{"cell_type":"markdown","metadata":{"id":"GhbL_IgBh8nR","colab_type":"text"},"source":["Split our data into features, labels, training, and testing data."]},{"cell_type":"code","metadata":{"id":"VyD_Nbs36uj2","colab_type":"code","colab":{}},"source":["### DO NOT MODIFY ###\n","# Load the CIFAR-10 dataset from Keras\n","# Split dataset into testing, traing, features, and labels\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R-zfgHq1CiQf","colab_type":"text"},"source":["# Exploratory Analysis"]},{"cell_type":"markdown","metadata":{"id":"f12apxSyCogM","colab_type":"text"},"source":["Now let's take a look at the size, shape, and dimensions of our intial data."]},{"cell_type":"code","metadata":{"id":"QFC1v84_ClYK","colab_type":"code","colab":{}},"source":["# Display the size and shape of features, labels, training, and testing datasets\n","print(\"Size and shape of the training features are: {}\".format(x_train.shape))\n","print(\"Size and shape of the training labels are: {}\".format(y_train.shape))\n","print(\"Size and shape of the testing features are: {}\".format(x_test.shape))\n","print(\"Size and shape of the testing labels are: {}\".format(y_test.shape))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WCOimgMYmg-9","colab_type":"text"},"source":["In case you are interest in looking at individual images, run the snippet of code below. You can change the index from 10 to another number within the training data to see what image shows up that will be fed to our network."]},{"cell_type":"code","metadata":{"id":"J-NR72dFjcig","colab_type":"code","colab":{}},"source":["# This samples the 10-th image from the training dataset.\n","index = 10 # change this value to see another image\n","image = x_train[index]\n","\n","### DO NOT MODIFY ###\n","# Display the image and its label.\n","plt.figure(figsize=(3,3)) # Initialize the size of the plot frame\n","plt.imshow(image); plt.grid('off');plt.axis('off') # Feed image values to plot\n","plt.show() # Generate plot onto screen"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zoTNTm7T9l8X","colab_type":"text"},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"ZVarEcnVe168","colab_type":"text"},"source":["We'll take care of the image preprocessing, but take a look if you are interested in how we manage the data before we feed it into our model."]},{"cell_type":"code","metadata":{"id":"cOg4VJKDDIBN","colab_type":"code","colab":{}},"source":["### DO NOT MODIFY ###\n","# Specify the number of class labels in our data\n","num_classes = 10\n","\n","# Keep original labels\n","labels_test = y_test\n","\n","# Labels are stored as unique integers\n","# Convert labels into unique one-hot encodings of length num_class\n","# Each label will then be converted to a series of zeros with one unique column containing a one for a unique label\n","# example 10000000000 or 0001000000, etc (don't worry if you are not familiar with this step)\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7rb5v37_8Rk","colab_type":"code","colab":{}},"source":["### DO NOT MODIFY ###\n","# Our input data is pixels from images where each pixel value is between ranges 0-255\n","# Range of values make it difficult for our network to learn\n","# Convert raw pixel values into values between 0-1\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 250.0\n","x_test /= 250.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ark3t6go9QWB","colab_type":"text"},"source":["# Model Building"]},{"cell_type":"markdown","metadata":{"id":"S09EpapGdiPz","colab_type":"text"},"source":["Alright now it's your turn! We went ahead and created the outline of what you will need to do to construct your model and get it up and running. If you have not heard of some of the terms used in this notebook such as convolutions, maxpooling, or softmax don't worry you are not expected to know what these functions do yet!\n","\n","For now, we have constructed the ConvMaxLayer and ForwardLayer wrappers so you can focus constructing your model by taking a look at comments provided along with the MNIST mini-project demo to see how such a model might be constructed. If the comments and demo are still not clear - please refer to the documentation listed above to learn more or ask for some help!"]},{"cell_type":"code","metadata":{"id":"12rhxceNfjGC","colab_type":"code","colab":{}},"source":["### DO NOT MODIFY ###\n","# Forward-Feed Neural Network Layer\n","class ForwardLayer(tf.keras.Model):\n","  \n","    # Initialize our variables\n","    def __init__(self, size, dropout_rate):\n","        super(ForwardLayer, self).__init__()\n","        self.size = size\n","        self.dropout_rate = dropout_rate\n","        \n","    # Define our layers\n","    def build(self, input_shape):\n","        self.dense = tf.keras.layers.Dense(self.size, input_shape=input_shape)\n","        self.batchnorm = tf.keras.layers.BatchNormalization()\n","        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n","    \n","    # Computation of network layers\n","    def call(self, inputs):\n","        x = self.dense(inputs)\n","        x = self.batchnorm(x)\n","        x = tf.nn.relu(x)\n","        x = self.dropout(x)\n","        return x\n","      \n","    # Define output shape\n","    def compute_output_shape(self, input_shape):\n","      return (input_shape[0], self.size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9F2xVrkDMMQy","colab_type":"code","colab":{}},"source":["# Initialize our network object\n","net = tf.keras.Sequential()\n","train = False # Freeze the Convolutional Blocks from being trained\n","\n","# Convolutional Block One\n","net.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='valid', input_shape=(32,32,3), trainable=train, name='conv_1'))\n","net.add(tf.keras.layers.BatchNormalization(trainable=train, name='bn_2'))\n","net.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid', trainable=train, name='maxpl_3'))\n","net.add(tf.keras.layers.Dropout(0.3, trainable=train, name='drp_4'))\n","   \n","# Convolutional Block Two\n","net.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='valid', trainable=train, name='conv_5'))\n","net.add(tf.keras.layers.BatchNormalization(trainable=train, name='bn_6'))\n","net.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid', trainable=train, name='maxpl_7'))\n","net.add(tf.keras.layers.Dropout(0.3, trainable=train, name='drp_8'))\n","\n","# Convolutional Block Three\n","net.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='valid', trainable=train, name='conv_9'))\n","net.add(tf.keras.layers.BatchNormalization(trainable=train, name='bn_10'))\n","net.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid', trainable=train, name='maxpl_11'))\n","net.add(tf.keras.layers.Dropout(0.2, trainable=train, name='drp_12'))\n","\n","# Flatten\n","net.add(tf.keras.layers.Flatten(name='flt_13'))\n","  \n","### TO DO: DEFINE THE DENSE PORTION OF THE NETWORK ###\n","# Create first forward-feed layer\n","# Add: a forward layer: ForwardLayer(size_of_layer, drop_out_prob, input_shape)\n","  \n","# Add more forward-feed layers (Optional)\n","# Add: a forward layer: ForwardLayer(size_of_layer, drop_out_prob, input_shape)\n","\n","### DO NOT MODIFY ###\n","# Output Layer\n","net.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qUXBGGm8f1U2","colab_type":"text"},"source":["Now that you have your model defined we'll need to actually build it and define how it will learn. To do so we'll need to call the network's compile function to provide it the loss, optimization, and metric parameters."]},{"cell_type":"code","metadata":{"id":"rnthsoyZPFwN","colab_type":"code","colab":{}},"source":["### DO NOT MODIFY ###\n","# The compile function will build our model by using the defined loss, optimization, and metric parameters\n","net.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print('Model is done compiling!')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vr9N678HfqGN","colab_type":"text"},"source":["# Load Pre-Trained Weights"]},{"cell_type":"markdown","metadata":{"id":"fbSTkX_5rHvW","colab_type":"text"},"source":["While we could train out model from the very start as we did with the MNIST project this would take a long time for this dataset.\n","\n","As promised in the MNIST mini-project we'll show you how to load a h5 file to your model to help with speedup that contains the pre-train weights for the convolution layers. However you will still need to train your dense layers you defined earlier before we can test and use it.\n","\n","To get access to the predefined weight file you can download it [here](https://drive.google.com/open?id=1ZPUGlYmdx57QfgcJMqpDxNfFWdpqTbe_)."]},{"cell_type":"code","metadata":{"id":"7pSot9elfrv9","colab_type":"code","colab":{}},"source":["# Load the pretrained_weights.h5 file\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QX9jfFiIrDwh","colab_type":"text"},"source":["Now that we have the pre-trained weights loaded we need to call the load_weights function to load them to our model. The weights are only for the convolution layers so we will still need to train our dense layers."]},{"cell_type":"code","metadata":{"id":"VEhc2bZ6ft0J","colab_type":"code","colab":{}},"source":["# File loads the weights for the pretrained convolutional network (allows us to focus on the forward-feed dense layers for faster training times)\n","net.load_weights('pretrained_weights.h5', by_name=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z9uR4CHMfv-J","colab_type":"code","colab":{}},"source":["# View the model before we train it\n","net.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eZ-ctaBX9dEa","colab_type":"text"},"source":["# Train Model"]},{"cell_type":"markdown","metadata":{"id":"aMDKyE-ogVSD","colab_type":"text"},"source":["Our next step is define the batch size and number of epochs to train before we call the network's fit procedure with all our data and training parameters listed below. \n","\n","The batch size refers to how many samples (in this case, samples = images) are processed by the model before the internal weights are updated. Naturally, this means the batch size will be anywhere between 1 (just one sample) and the size of the training set (all the samples in the training set). It is generally advantageous to set the batch size to a relatively small value such as 32 or 64 since that limits how much memory we use on each iteration. That is, we only load a handful of images at a time rather than all of them at once. \n","\n","\"Epoch\" is simply another word for iteration. The more epochs we run, the more the model is able to train and (hopefully) the lower the error rate will be. Of course, training takes time, so for this project we first recommend starting with between 2-3 epochs and see if you can get the model to have an accuracy above 50% (random guessing is about 10%). Next, play around with the various model and training parameters (such as the number of epochs), or add more layers to see if you can get the model above 70% percent."]},{"cell_type":"code","metadata":{"id":"N6YXEpulPtsn","colab_type":"code","colab":{}},"source":["### TO DO: TRAIN OUR NETWORK ###\n","# Use the fit function to give the network the training features, training labels, batch size, number of epochs to train, validation split size\n","net.fit(x_train, y_train, batch_size=\"Replace and define the batch size\", epochs=\"Replace and define the number of epochs to train\", validation_split=0.2, shuffle=True)\n","net.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FQu2LV8p9a0G","colab_type":"text"},"source":["# Test Model Performance"]},{"cell_type":"markdown","metadata":{"id":"0RsCL8JchNz1","colab_type":"text"},"source":["Now that we trained our model here is the moment of truth. A model that only performs well on training data is not a very good model! Let's see how well the model does on testing data to get an idea of how it might perform out in the wild. \n","\n","If you can get the model to predict images above 70% pat yourself on the back! These are really advanced networks that until just several years ago were extremely difficult for even top AI researchers to achieve!"]},{"cell_type":"code","metadata":{"id":"g2hQuSIbP8c6","colab_type":"code","colab":{}},"source":["### DO NOT MODIFY ###\n","# Use the networks evaluate function to see how well the model predicts the correct labels on the testing dataset\n","scores = net.evaluate(x_test, y_test, verbose=0)\n","\n","# Report the final accuracy score\n","print('Test Loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"19TOq0rX0i4r","colab_type":"text"},"source":["# Applications"]},{"cell_type":"markdown","metadata":{"id":"jSfJ7X502tKv","colab_type":"text"},"source":["Alright the moment has come, let's see how well our neural networks predicts each class object!"]},{"cell_type":"code","metadata":{"id":"Eo-TLhveECUy","colab_type":"code","colab":{}},"source":["### DO NOT MODIFY ###\n","# Create plot and parameters to layout our images and predictions\n","labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","num = 3\n","margin = 0.05\n","ind = np.arange(len(labels))\n","width = (1. - 2. * margin) / num\n","\n","fig, ax = plt.subplots(nrows=num, ncols=2)\n","fig.tight_layout()\n","fig.suptitle('Image Predictions', fontsize=20, y=1.1)\n","\n","# Loop through each image to plot and make a prediction\n","for i in range(num):\n","  image = x_test[i]\n","  label = labels[labels_test[i][0]]\n","  x = image.reshape(1,image.shape[0],image.shape[1],image.shape[2])\n","  pred = net.predict(x, batch_size=None, verbose=0, steps=None).flatten()\n","\n","  # Display image and correct label\n","  ax[i][0].imshow(image.squeeze())\n","  ax[i][0].set_title(\"Correct Label: {}\".format(label))\n","  ax[i][0].set_axis_off()\n","  \n","  # Display the predicted confidence in each label\n","  ax[i][1].barh(ind + margin, pred, width)\n","  ax[i][1].set_yticks(ind + margin)\n","  ax[i][1].set_yticklabels(labels)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HumSAtvGf-K2","colab_type":"text"},"source":["# Save Model"]},{"cell_type":"markdown","metadata":{"id":"L8gYm5u2sKj9","colab_type":"text"},"source":["In case you would like to continue working on your own model, make sure to save the weights and download the file to your local computer. For more information and tips on how to reload your model check out the documentation [here.](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model)"]},{"cell_type":"code","metadata":{"id":"Q5rDog4Hf9qB","colab_type":"code","colab":{}},"source":["# Saves your trained model for use later\n","net.save_weights('cifar_final_weights.h5') # Saves just the weights (like we did earlier)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wGqEqdQAgCK1","colab_type":"code","colab":{}},"source":["# Download the files to local computer drive\n","files.download('cifar_final_weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gByqhonKqiDL","colab_type":"text"},"source":["# Reflection and Analysis"]},{"cell_type":"markdown","metadata":{"id":"IbP6VoEQqmDU","colab_type":"text"},"source":["1.  What was the accuracy of your final model? \n","\n","2.  Did the training, validation, and testing accuracy differ significantly at the end of training?\n","\n","3. About how long did it take to train your final model?\n","\n","4.  What factors did you consider when you built your model? \n","\n","5.  What parameters did you play around with and consider? Did you notice any significant changes when you changed this parameter? What was the overall affect of the model's performance?\n","\n","6.  If you had more time do you think you could have produced a better model? If so what would you play around or experiment with in order to determine this? What factors might prevent your model from being able to accurately capture the data?\n","\n","7. How do you think you can apply this model to everyday applications? How do you thing it could help serve society?\n"]}]}